{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"The documentation is a work in progress. Quick Start Guide This page contains details of how you can build a simple model using NeuralProphet with minimal features. Install After downloading the code repository (via git clone ), change to the repository directory ( cd neural_prophet ) and install neuralprophet as python package with pip install . Note: If you plan to use the package in a Jupyter notebook, it is recommended to install the 'live' package version with pip install .[live] . This will allow you to enable plot_live_loss in the train function to get a live plot of train (and validation) loss. Import Now you can use NeuralProphet in your code: from neuralprophet import NeuralProphet Input Data The input data format expected by the neural_prophet package is the same as in original prophet . It should have two columns, ds which has the timestamps and y column which contains the observed values of the time series. Throughout this documentation, we will be using the time series data of the log daily page views for the Peyton Manning Wikipedia page. The data can be imported as follows. import pandas as pd df = pd.read_csv('../example_data/example_wp_log_peyton_manning.csv') The format of the data looks like below. ds y 2007-12-10 9.59 2007-12-11 8.52 2007-12-12 8.18 2007-12-13 8.07 2007-12-14 7.89 Simple Model A simple model with neural_prophet for this dataset can be fitted by creating an object of the NeuralProphet class as follows and calling the fit function. This fits a model with the default settings in the model. m = NeuralProphet() metrics = m.fit(df) Once the model is fitted, we can make forecasts using the fitted model. For this, we first need to create a future dataframe consisting of the time steps into the future that we need to forecast for. NeuralProphet provides the helper function make_future_dataframe for this purpose. future = m.make_future_dataframe(df, future_periods=365) forecast = m.predict(future) Plotting With the forecasts obtained from the model, you can visualize them. forecasts_plot = m.plot(forecast) This is a simple model with a trend and a weekly seasonality and a yearly seasonality. You can also look at the individual components separately. fig_comp = m.plot_components() The individual coefficient values can also be plotted as below to gain further insights. fig_param = m.plot_components() Validation Model validation for NeuralProphet can be done in two ways. Users can split the dataset manually to validate after the model fitting like below by specifying the fraction of data to be used for validation in the argument valida_p . This validation set is reserved from the end of the series. m = NeuralProphet() df_train, df_val = m.split_df(df, valid_p=0.2) train_metrics = m.fit(df_train) val_metrics = m.test(df_val) You can now look at the training and validation metrics separately. You can also perform validation per every epoch during model fitting. This is done as follows by setting the validate_each_epoch argument in the fit function call. # or evaluate while training m = NeuralProphet() metrics = m.fit(df, validate_each_epoch=True, valid_p=0.2)","title":"Quickstart"},{"location":"#quick-start-guide","text":"This page contains details of how you can build a simple model using NeuralProphet with minimal features.","title":"Quick Start Guide"},{"location":"#install","text":"After downloading the code repository (via git clone ), change to the repository directory ( cd neural_prophet ) and install neuralprophet as python package with pip install . Note: If you plan to use the package in a Jupyter notebook, it is recommended to install the 'live' package version with pip install .[live] . This will allow you to enable plot_live_loss in the train function to get a live plot of train (and validation) loss.","title":"Install"},{"location":"#import","text":"Now you can use NeuralProphet in your code: from neuralprophet import NeuralProphet","title":"Import"},{"location":"#input-data","text":"The input data format expected by the neural_prophet package is the same as in original prophet . It should have two columns, ds which has the timestamps and y column which contains the observed values of the time series. Throughout this documentation, we will be using the time series data of the log daily page views for the Peyton Manning Wikipedia page. The data can be imported as follows. import pandas as pd df = pd.read_csv('../example_data/example_wp_log_peyton_manning.csv') The format of the data looks like below. ds y 2007-12-10 9.59 2007-12-11 8.52 2007-12-12 8.18 2007-12-13 8.07 2007-12-14 7.89","title":"Input Data"},{"location":"#simple-model","text":"A simple model with neural_prophet for this dataset can be fitted by creating an object of the NeuralProphet class as follows and calling the fit function. This fits a model with the default settings in the model. m = NeuralProphet() metrics = m.fit(df) Once the model is fitted, we can make forecasts using the fitted model. For this, we first need to create a future dataframe consisting of the time steps into the future that we need to forecast for. NeuralProphet provides the helper function make_future_dataframe for this purpose. future = m.make_future_dataframe(df, future_periods=365) forecast = m.predict(future)","title":"Simple Model"},{"location":"#plotting","text":"With the forecasts obtained from the model, you can visualize them. forecasts_plot = m.plot(forecast) This is a simple model with a trend and a weekly seasonality and a yearly seasonality. You can also look at the individual components separately. fig_comp = m.plot_components() The individual coefficient values can also be plotted as below to gain further insights. fig_param = m.plot_components()","title":"Plotting"},{"location":"#validation","text":"Model validation for NeuralProphet can be done in two ways. Users can split the dataset manually to validate after the model fitting like below by specifying the fraction of data to be used for validation in the argument valida_p . This validation set is reserved from the end of the series. m = NeuralProphet() df_train, df_val = m.split_df(df, valid_p=0.2) train_metrics = m.fit(df_train) val_metrics = m.test(df_val) You can now look at the training and validation metrics separately. You can also perform validation per every epoch during model fitting. This is done as follows by setting the validate_each_epoch argument in the fit function call. # or evaluate while training m = NeuralProphet() metrics = m.fit(df, validate_each_epoch=True, valid_p=0.2)","title":"Validation"},{"location":"contribute/","text":"Contribute Dev Install After downloading the code repository (via git clone ), change to the repository directory ( cd neural_prophet ), activate your virtual environment, and install neuralprophet as python package with pip install -e .[dev] (Including the optional -e flag will install neuralprophet in \"editable\" mode, meaning that instead of copying the files into your virtual environment, a symlink will be created to the files where they are.) Additionally you must run $ neuralprophet_dev_setup in your console to run the dev-setup script which installs appropriate git hooks for testing etc. Notes As far as possible, we follow the Google Python Style Guide As for Git practices, please follow the steps described at Swiss Cheese for how to git-rebase-squash when working on a forked repo.","title":"Contribute"},{"location":"contribute/#contribute","text":"","title":"Contribute"},{"location":"contribute/#dev-install","text":"After downloading the code repository (via git clone ), change to the repository directory ( cd neural_prophet ), activate your virtual environment, and install neuralprophet as python package with pip install -e .[dev] (Including the optional -e flag will install neuralprophet in \"editable\" mode, meaning that instead of copying the files into your virtual environment, a symlink will be created to the files where they are.) Additionally you must run $ neuralprophet_dev_setup in your console to run the dev-setup script which installs appropriate git hooks for testing etc.","title":"Dev Install"},{"location":"contribute/#notes","text":"As far as possible, we follow the Google Python Style Guide As for Git practices, please follow the steps described at Swiss Cheese for how to git-rebase-squash when working on a forked repo.","title":"Notes"},{"location":"model-overview/","text":"Overview of the NeuralProphet Model NeuralProphet is a Neural Network based PyTorch implementation of a user-friendly time series forecasting tool for practitioners. This is heavily inspired by Prophet , which is the popular forecasting tool developed by Facebook. NeuralProphet is developed in a fully modular architecture which makes it scalable to add any additional components in the future. Our vision is to develop a simple to use forecasting tool for users while retaining the original objectives of Prophet such as interpretability, configurability and providing much more such as the automatic differencing capabilities by using PyTorch as the backend. Time Series Components NeuralProphet is a decomposable time series model with the components, trend, seasonality, auto-regression, special events, future regressors and lagged regressors. Future regressors are external variables which have known future values for the forecast period whereas the lagged regressors are those external variables which only have values for the observed period. Trend can be modelled either as a linear or a piece-wise linear trend by using changepoints. Seasonality is modelled using fourier terms and thus can handle multiple seasonalities for high-frequency data. Auto-regression is handled using an implementation of AR-Net , an Auto-Regressive Feed-Forward Neural Network for time series. Lagged regressors are also modelled using separate Feed-Forward Neural Networks. Future regressors and special events are both modelled as covariates of the model with dedicated coefficients. For more details, refer to the documentation of the individual components. Data Preprocessing We perform a few data pre-processing steps in the model. For the observed values of the time series, users can specify whether they would like the values to be normalized. By default, the y values would be min-max normalized. If the user specifically, sets the normalize_y argument to true , the data is z-score normalized. Normalization can be performed for covariates as well. The default mode for normalization of covariates is auto . In this mode, apart from binary features such as events, all others are z-score normalized. We also perform an imputation in-case there are missing values in the data. However, imputation is only done if auto-regression is enabled in the model. Otherwise, the missing values do not really matter for the regression model. No special imputation is done for binary data. They are simply taken as 0 for the missing dates. For the numeric data, including the y values, normalization is a two-step process. First, small gaps are filled with a linear imputation and then the more larger gaps are filled with rolling averages. When auto-regression is enabled, the observed y values are preprocessed in a moving window format to learn from lagged values. This is done for lagged regressors as well. When to Use NeuralProphet NeuralProphet can produce both single step and multi step-ahead forecasts. At the moment, NeuralProphet builds models univariately. This means that if you have many series that you expect to produce forecasts for, you need to do this one at a time. However, in future we hope to integrate the capability of global forecasting models into NeuralProphet. NeuralProphet helps build forecasting models for scenarios where there are other external factors which can drive the behaviour of the target series over time. Using such external information can heavily improve forecasting models rather than relying only on the autocorrelation of the series. NeuralProphet tool is suitable for forecasting practitioners that wish to gain insights into the overall modelling process by visualizing the forecasts, the individual components as well as the underlying coefficients of the model. Through our descriptive plots, users can visualize the interaction of the individual components. They also have the power to control these coefficients as required by introducing sparsity through regularization. They can combine the components additively or multiplicatively as per their domain knowledge. This is an ongoing effort. Therefore, NeuralProphet will be equipped with even much more features in the upcoming releases.","title":"Model Overview"},{"location":"model-overview/#overview-of-the-neuralprophet-model","text":"NeuralProphet is a Neural Network based PyTorch implementation of a user-friendly time series forecasting tool for practitioners. This is heavily inspired by Prophet , which is the popular forecasting tool developed by Facebook. NeuralProphet is developed in a fully modular architecture which makes it scalable to add any additional components in the future. Our vision is to develop a simple to use forecasting tool for users while retaining the original objectives of Prophet such as interpretability, configurability and providing much more such as the automatic differencing capabilities by using PyTorch as the backend.","title":"Overview of the NeuralProphet Model"},{"location":"model-overview/#time-series-components","text":"NeuralProphet is a decomposable time series model with the components, trend, seasonality, auto-regression, special events, future regressors and lagged regressors. Future regressors are external variables which have known future values for the forecast period whereas the lagged regressors are those external variables which only have values for the observed period. Trend can be modelled either as a linear or a piece-wise linear trend by using changepoints. Seasonality is modelled using fourier terms and thus can handle multiple seasonalities for high-frequency data. Auto-regression is handled using an implementation of AR-Net , an Auto-Regressive Feed-Forward Neural Network for time series. Lagged regressors are also modelled using separate Feed-Forward Neural Networks. Future regressors and special events are both modelled as covariates of the model with dedicated coefficients. For more details, refer to the documentation of the individual components.","title":"Time Series Components"},{"location":"model-overview/#data-preprocessing","text":"We perform a few data pre-processing steps in the model. For the observed values of the time series, users can specify whether they would like the values to be normalized. By default, the y values would be min-max normalized. If the user specifically, sets the normalize_y argument to true , the data is z-score normalized. Normalization can be performed for covariates as well. The default mode for normalization of covariates is auto . In this mode, apart from binary features such as events, all others are z-score normalized. We also perform an imputation in-case there are missing values in the data. However, imputation is only done if auto-regression is enabled in the model. Otherwise, the missing values do not really matter for the regression model. No special imputation is done for binary data. They are simply taken as 0 for the missing dates. For the numeric data, including the y values, normalization is a two-step process. First, small gaps are filled with a linear imputation and then the more larger gaps are filled with rolling averages. When auto-regression is enabled, the observed y values are preprocessed in a moving window format to learn from lagged values. This is done for lagged regressors as well.","title":"Data Preprocessing"},{"location":"model-overview/#when-to-use-neuralprophet","text":"NeuralProphet can produce both single step and multi step-ahead forecasts. At the moment, NeuralProphet builds models univariately. This means that if you have many series that you expect to produce forecasts for, you need to do this one at a time. However, in future we hope to integrate the capability of global forecasting models into NeuralProphet. NeuralProphet helps build forecasting models for scenarios where there are other external factors which can drive the behaviour of the target series over time. Using such external information can heavily improve forecasting models rather than relying only on the autocorrelation of the series. NeuralProphet tool is suitable for forecasting practitioners that wish to gain insights into the overall modelling process by visualizing the forecasts, the individual components as well as the underlying coefficients of the model. Through our descriptive plots, users can visualize the interaction of the individual components. They also have the power to control these coefficients as required by introducing sparsity through regularization. They can combine the components additively or multiplicatively as per their domain knowledge. This is an ongoing effort. Therefore, NeuralProphet will be equipped with even much more features in the upcoming releases.","title":"When to Use NeuralProphet"},{"location":"model/auto-regression/","text":"Modelling Auto-Regression AR-Net can be enabled in the NeuralProphet by simply setting an appropriate value to the n_lags parameter of the NeuralProphet object. m = NeuralProphet( n_forecasts=3, n_lags=5, yearly_seasonality=False, weekly_seasonality=False, daily_seasonality=False, ) In the above example, we create a forecasting scenario which feeds 5 lags into AR-Net and receives 3 steps as forecasts. Once you have the AR-Net enabled, during forecasting your future_periods value should be equal to the n_forecasts value specified when creating the NeuralProphet object. Whichever value you specify for future_periods , it will be converted to the value of n_forecasts with a notice to the user. This is because, since the AR-Net is built during training such that it has an ouptut size of n_forecasts , it cannot support any other value during testing. The plotted components should look like below. You can now see auto-regression as a separate component. The corresponding coefficients look like below. You can see the relevance of each of the lags when modelling the autocorrelation. You can also specify the num_hidden_layers for the AR-Net. m = NeuralProphet( n_forecasts=3, n_lags=5, num_hidden_layers=2, yearly_seasonality=False, weekly_seasonality=False, daily_seasonality=False ) Regularization in AR-Net is done by setting the ar_sparsity parameter in the NeuralProphet object like below. ar_sparsity should take a value in between 0-1. m = NeuralProphet( n_forecasts=3, n_lags=5, num_hidden_layers=2, ar_sparsity=0.01, yearly_seasonality=False, weekly_seasonality=False, daily_seasonality=False )","title":"Auto-Regression"},{"location":"model/auto-regression/#modelling-auto-regression","text":"AR-Net can be enabled in the NeuralProphet by simply setting an appropriate value to the n_lags parameter of the NeuralProphet object. m = NeuralProphet( n_forecasts=3, n_lags=5, yearly_seasonality=False, weekly_seasonality=False, daily_seasonality=False, ) In the above example, we create a forecasting scenario which feeds 5 lags into AR-Net and receives 3 steps as forecasts. Once you have the AR-Net enabled, during forecasting your future_periods value should be equal to the n_forecasts value specified when creating the NeuralProphet object. Whichever value you specify for future_periods , it will be converted to the value of n_forecasts with a notice to the user. This is because, since the AR-Net is built during training such that it has an ouptut size of n_forecasts , it cannot support any other value during testing. The plotted components should look like below. You can now see auto-regression as a separate component. The corresponding coefficients look like below. You can see the relevance of each of the lags when modelling the autocorrelation. You can also specify the num_hidden_layers for the AR-Net. m = NeuralProphet( n_forecasts=3, n_lags=5, num_hidden_layers=2, yearly_seasonality=False, weekly_seasonality=False, daily_seasonality=False ) Regularization in AR-Net is done by setting the ar_sparsity parameter in the NeuralProphet object like below. ar_sparsity should take a value in between 0-1. m = NeuralProphet( n_forecasts=3, n_lags=5, num_hidden_layers=2, ar_sparsity=0.01, yearly_seasonality=False, weekly_seasonality=False, daily_seasonality=False )","title":"Modelling Auto-Regression"},{"location":"model/events/","text":"Modelling Events Often in forecasting problems, we need to consider recurring special events. These are supported by neural_prophet . These events can be added both in additive format and multiplicative format. To provide the information of events into the model, the user has to create a dataframe which has the column ds corresponding to the event dates and the column event whcih contains the names of the events on a specified dates. In the following example we have created the dataframe named history_events_df which contains these events information. playoffs_history = pd.DataFrame({ 'event': 'playoff', 'ds': pd.to_datetime(['2008-01-13', '2009-01-03', '2010-01-16', '2010-01-24', '2010-02-07', '2011-01-08', '2013-01-12', '2014-01-12', '2014-01-19', '2014-02-02', '2015-01-11', '2016-01-17']), }) superbowls_history = pd.DataFrame({ 'event': 'superbowl', 'ds': pd.to_datetime(['2010-02-07', '2014-02-02']), }) history_events_df = pd.concat((playoffs_history, superbowls_history)) The first few rows of the history_events_df dataframe looks like below. event ds 0 playoff 2008-01-13 00:00:00 1 playoff 2009-01-03 00:00:00 2 playoff 2010-01-16 00:00:00 3 playoff 2010-01-24 00:00:00 4 playoff 2010-02-07 00:00:00 5 playoff 2011-01-08 00:00:00 For forecasting, we also need to provide the future dates of these events used to train the model. You can either include these in the same events dataframe that was created before for fitting the model, or in a new dataframe as follows. playoffs_future = pd.DataFrame({ 'event': 'playoff', 'ds': pd.to_datetime(['2016-01-21', '2016-02-07']) }) superbowl_future = pd.DataFrame({ 'event': 'superbowl', 'ds': pd.to_datetime(['2016-01-23', '2016-02-07']) }) future_events_df = pd.concat((playoffs_future, superbowl_future)) Once the events dataframes have been created, the NeuralProphet object should be created and the events configs should be added. This is done using the add_events function of the NeuralProphet class. m = NeuralProphet( n_forecasts=10, yearly_seasonality=False, weekly_seasonality=False, daily_seasonality=False, ) m = m.add_events([\"superbowl\", \"playoff\"]) After that, we need to convert the events data in the previously created dataframes into the binary input data expected by the model. This can be done by calling the create_df_with_events function by passing original time series dataframe along with the created history_events_df . history_df = m.create_df_with_events(df, history_events_df) This returns a dataframe in the following format. ds y superbowl playoff 0 2007-12-10 00:00:00 9.59076 0 0 1 2007-12-11 00:00:00 8.51959 0 0 2 2007-12-12 00:00:00 8.18368 0 0 3 2007-12-13 00:00:00 8.07247 0 0 4 2007-12-14 00:00:00 7.89357 0 0 After that, we can simply fit the model as below. metrics = m.fit(history_df) To do forecasting with the fitted model, we first need to create the future dataframe with events information. This can be done with the make_future_dataframe function by passing in the created future_events_df and specifying the desired size of the forecast horizon. future = m.make_future_dataframe(df=history_df, events_df=future_events_df, future_periods=10) forecast = m.predict(df=future) The produced forecasts look like below. The 10 step-ahead forecasts are available in the yhat1 column. The components from the individual events are available in the event_playoff and event_superbowl columns and their agrgegated effect is shown on the events_additive column. ds y yhat1 residual1 trend events_additive event_playoff event_superbowl 0 2016-01-21 00:00:00 7.34693 nan -0.583201 -0.208826 -0.208826 0 1 2016-01-22 00:00:00 7.55506 nan -0.5839 0 0 0 2 2016-01-23 00:00:00 6.95665 nan -0.584599 -0.597706 0 -0.597706 3 2016-01-24 00:00:00 7.55366 nan -0.585297 0 0 0 4 2016-01-25 00:00:00 7.55296 nan -0.585997 0 0 0 5 2016-01-26 00:00:00 7.55226 nan -0.586695 0 0 0 6 2016-01-27 00:00:00 7.55156 nan -0.587394 0 0 0 7 2016-01-28 00:00:00 7.55087 nan -0.588093 0 0 0 8 2016-01-29 00:00:00 7.55017 nan -0.588792 0 0 0 9 2016-01-30 00:00:00 7.54947 nan -0.58949 0 0 0 The different components can be plotted like below. All events are plotted as one component, the Additive Events fig_comp = m.plot_components(forecast) If you want to have a look at the coefficients of the events, the plot_parameters function is helpful. fig_param = m.plot_parameters() Multiplicative Events The default mode for events in neural_prophet is additive. However, events can also be modelled in a multiplicative format. For this, when adding the events configs to the NeuralProphet object, we need to set the mode to multiplicative as below. m = m.add_events([\"superbowl\", \"playoff\"], mode=\"multiplicative\") All the other steps are the same as for the additive mode. Now, when you plot the components, the event components will appear as percentages. In the same manner, the coefficients too, will now appear as percentages when plotted. Event Windows You can also provide windows for events. This way, you can consider the days around a particular event also as special events by providing the arguments lower_window and upper_window as appropriate to the add_events function of the NeuralProphet object. By default, the values for these windows are 0 , which means windows are not considered. m = m.add_events([\"superbowl\", \"playoff\"], lower_window=-1, upper_window=1) According to this specification, for both superbowl and playoff events, three special events will be modelled, the event date, the previous day and the next day. These will be visible in the component plots as below. In the parameters plot too, there will now be superbowl_+1 and superbowl_-1 which correspond to the coefficients of the day following and previous to the superbowl event. The playoff event also has the same new coefficients. If you want to define different windows for the individual events, this can also be done as follows. m = m.add_events(\"superbowl\", lower_window=-1, upper_window=1) m = m.add_events(\"playoff\", upper_window=2) In the above example, for the playoff event, the specified event date, as well as the two following dates are considered as three different special events. Country Specific Holidays Apart from the user specified events, neural_prophet also supports standard country specific holidays. If you want to add the holidays for a particualr country, you simply have to call the add_country_holidays function on the NeuralProphet object and specify the country. Similar to the user specified events, country specific holidays can either be additive or multiplicative and include windows. However, unlike for user specified events, the windows will be the same for all the country specific events. m = m.add_country_holidays(\"US\", mode=\"additive\", lower_window=-1, upper_window=1) This example will add all the US holidays into the model in additive format. The coefficients of the individual events will now look like below. Regularization for Events Events can also support regularization of the coefficients. You can specify the regularization when adding the event configs into the NeuralProphet object like below. m = m.add_events([\"superbowl\", \"playoff\"], regularization=0.05) The regularization for the individual events can also be different from each other like below. m = m.add_events(\"superbowl\", regularization=0.05) m = m.add_events(\"playoff\", regularization=0.03) For the country specific holidays too, regularizations can be specified like below. m = m.add_country_holidays(\"US\", mode=\"additive\", regularization=0.05)","title":"Events"},{"location":"model/events/#modelling-events","text":"Often in forecasting problems, we need to consider recurring special events. These are supported by neural_prophet . These events can be added both in additive format and multiplicative format. To provide the information of events into the model, the user has to create a dataframe which has the column ds corresponding to the event dates and the column event whcih contains the names of the events on a specified dates. In the following example we have created the dataframe named history_events_df which contains these events information. playoffs_history = pd.DataFrame({ 'event': 'playoff', 'ds': pd.to_datetime(['2008-01-13', '2009-01-03', '2010-01-16', '2010-01-24', '2010-02-07', '2011-01-08', '2013-01-12', '2014-01-12', '2014-01-19', '2014-02-02', '2015-01-11', '2016-01-17']), }) superbowls_history = pd.DataFrame({ 'event': 'superbowl', 'ds': pd.to_datetime(['2010-02-07', '2014-02-02']), }) history_events_df = pd.concat((playoffs_history, superbowls_history)) The first few rows of the history_events_df dataframe looks like below. event ds 0 playoff 2008-01-13 00:00:00 1 playoff 2009-01-03 00:00:00 2 playoff 2010-01-16 00:00:00 3 playoff 2010-01-24 00:00:00 4 playoff 2010-02-07 00:00:00 5 playoff 2011-01-08 00:00:00 For forecasting, we also need to provide the future dates of these events used to train the model. You can either include these in the same events dataframe that was created before for fitting the model, or in a new dataframe as follows. playoffs_future = pd.DataFrame({ 'event': 'playoff', 'ds': pd.to_datetime(['2016-01-21', '2016-02-07']) }) superbowl_future = pd.DataFrame({ 'event': 'superbowl', 'ds': pd.to_datetime(['2016-01-23', '2016-02-07']) }) future_events_df = pd.concat((playoffs_future, superbowl_future)) Once the events dataframes have been created, the NeuralProphet object should be created and the events configs should be added. This is done using the add_events function of the NeuralProphet class. m = NeuralProphet( n_forecasts=10, yearly_seasonality=False, weekly_seasonality=False, daily_seasonality=False, ) m = m.add_events([\"superbowl\", \"playoff\"]) After that, we need to convert the events data in the previously created dataframes into the binary input data expected by the model. This can be done by calling the create_df_with_events function by passing original time series dataframe along with the created history_events_df . history_df = m.create_df_with_events(df, history_events_df) This returns a dataframe in the following format. ds y superbowl playoff 0 2007-12-10 00:00:00 9.59076 0 0 1 2007-12-11 00:00:00 8.51959 0 0 2 2007-12-12 00:00:00 8.18368 0 0 3 2007-12-13 00:00:00 8.07247 0 0 4 2007-12-14 00:00:00 7.89357 0 0 After that, we can simply fit the model as below. metrics = m.fit(history_df) To do forecasting with the fitted model, we first need to create the future dataframe with events information. This can be done with the make_future_dataframe function by passing in the created future_events_df and specifying the desired size of the forecast horizon. future = m.make_future_dataframe(df=history_df, events_df=future_events_df, future_periods=10) forecast = m.predict(df=future) The produced forecasts look like below. The 10 step-ahead forecasts are available in the yhat1 column. The components from the individual events are available in the event_playoff and event_superbowl columns and their agrgegated effect is shown on the events_additive column. ds y yhat1 residual1 trend events_additive event_playoff event_superbowl 0 2016-01-21 00:00:00 7.34693 nan -0.583201 -0.208826 -0.208826 0 1 2016-01-22 00:00:00 7.55506 nan -0.5839 0 0 0 2 2016-01-23 00:00:00 6.95665 nan -0.584599 -0.597706 0 -0.597706 3 2016-01-24 00:00:00 7.55366 nan -0.585297 0 0 0 4 2016-01-25 00:00:00 7.55296 nan -0.585997 0 0 0 5 2016-01-26 00:00:00 7.55226 nan -0.586695 0 0 0 6 2016-01-27 00:00:00 7.55156 nan -0.587394 0 0 0 7 2016-01-28 00:00:00 7.55087 nan -0.588093 0 0 0 8 2016-01-29 00:00:00 7.55017 nan -0.588792 0 0 0 9 2016-01-30 00:00:00 7.54947 nan -0.58949 0 0 0 The different components can be plotted like below. All events are plotted as one component, the Additive Events fig_comp = m.plot_components(forecast) If you want to have a look at the coefficients of the events, the plot_parameters function is helpful. fig_param = m.plot_parameters()","title":"Modelling Events"},{"location":"model/events/#multiplicative-events","text":"The default mode for events in neural_prophet is additive. However, events can also be modelled in a multiplicative format. For this, when adding the events configs to the NeuralProphet object, we need to set the mode to multiplicative as below. m = m.add_events([\"superbowl\", \"playoff\"], mode=\"multiplicative\") All the other steps are the same as for the additive mode. Now, when you plot the components, the event components will appear as percentages. In the same manner, the coefficients too, will now appear as percentages when plotted.","title":"Multiplicative Events"},{"location":"model/events/#event-windows","text":"You can also provide windows for events. This way, you can consider the days around a particular event also as special events by providing the arguments lower_window and upper_window as appropriate to the add_events function of the NeuralProphet object. By default, the values for these windows are 0 , which means windows are not considered. m = m.add_events([\"superbowl\", \"playoff\"], lower_window=-1, upper_window=1) According to this specification, for both superbowl and playoff events, three special events will be modelled, the event date, the previous day and the next day. These will be visible in the component plots as below. In the parameters plot too, there will now be superbowl_+1 and superbowl_-1 which correspond to the coefficients of the day following and previous to the superbowl event. The playoff event also has the same new coefficients. If you want to define different windows for the individual events, this can also be done as follows. m = m.add_events(\"superbowl\", lower_window=-1, upper_window=1) m = m.add_events(\"playoff\", upper_window=2) In the above example, for the playoff event, the specified event date, as well as the two following dates are considered as three different special events.","title":"Event Windows"},{"location":"model/events/#country-specific-holidays","text":"Apart from the user specified events, neural_prophet also supports standard country specific holidays. If you want to add the holidays for a particualr country, you simply have to call the add_country_holidays function on the NeuralProphet object and specify the country. Similar to the user specified events, country specific holidays can either be additive or multiplicative and include windows. However, unlike for user specified events, the windows will be the same for all the country specific events. m = m.add_country_holidays(\"US\", mode=\"additive\", lower_window=-1, upper_window=1) This example will add all the US holidays into the model in additive format. The coefficients of the individual events will now look like below.","title":"Country Specific Holidays"},{"location":"model/events/#regularization-for-events","text":"Events can also support regularization of the coefficients. You can specify the regularization when adding the event configs into the NeuralProphet object like below. m = m.add_events([\"superbowl\", \"playoff\"], regularization=0.05) The regularization for the individual events can also be different from each other like below. m = m.add_events(\"superbowl\", regularization=0.05) m = m.add_events(\"playoff\", regularization=0.03) For the country specific holidays too, regularizations can be specified like below. m = m.add_country_holidays(\"US\", mode=\"additive\", regularization=0.05)","title":"Regularization for Events"},{"location":"model/future-regressors/","text":"Modelling Future Regressors Future regressors are the external variables which have known future values. In that sense, the future regressors functionality if very similar to special events. The past values of these regressors corresponding to the training time stamps, have to be provided along with the training data itself. See below for an example where we create two dummy regressors A and B by taking rolling means of the original data. df['A'] = df['y'].rolling(7, min_periods=1).mean() df['B'] = df['y'].rolling(30, min_periods=1).mean() The dataframe created likewise, should look like below. ds y A B 0 2007-12-10 9.59076 9.59076 9.59076 1 2007-12-11 8.51959 9.05518 9.05518 2 2007-12-12 8.18368 8.76468 8.76468 3 2007-12-13 8.07247 8.59162 8.59162 4 2007-12-14 7.89357 8.45201 8.45201 In order to perform forecasting, we also need to provide the future values of the regressors. future_regressors_df = pd.DataFrame(data={'A': df['A'][:50], 'B': df['B'][:50]}) This dataframe looks like below. A B 0 9.59076 9.59076 1 9.05518 9.05518 2 8.76468 8.76468 3 8.59162 8.59162 4 8.45201 8.45201 It is a dataframe with only the columns of the future values of the regressors. Similar to events, future regressors too can be added in both the additive and multiplicative formats. Additive Future Regressors The default mode for future regressors in neural_prophet is additive. The regressors have to be added to the NeuralProphet object by calling the add_future_regressor function. Once this is done, the model can be fitted by providing to the fit function, the dataframe of the training data as well as the regressor values. m = NeuralProphet( n_forecasts=3, n_lags=5, ) m = m.add_future_regressor(name='A') m = m.add_future_regressor(name='B') metrics = m.fit(df) When forecasting, the future dataframe must be created by providing the future values of the regressors. To do that, now you need to call the make_future_dataframe function by providing the previously created future_regressors_df as an argument. future = m.make_future_dataframe(df=df, regressors_df=future_regressors_df, future_periods=3) forecast = m.predict(df=future) Now you can plot the components the same way and the resulting plot would look something like below. fig_comp = m.plot_components(forecast) In addition to the components like seasonality, auto-regression and trend it also shows a plot for the additive future regressors. The coefficients of the future regressors can also be plotted. fig_param = m.plot_parameters() Multiplicative Future Regressors Future regressors can also be added in multiplicative mode. You simply need to set the mode to multiplicative when adding the regressors to the NeuralProphet object. m = m.add_future_regressor(name='A', mode=\"multiplicative\") m = m.add_future_regressor(name='B') In the above example, we have both additive and multiplicative regressors, where A is multiplicative and B is additive. All the other steps in the fitting and the forecasting processes are the same. The components plot looks as below. There are two individual plots for the additive and multiplicative regressors, where the multiplicative component is shown as a percentage. In the same manner, the coefficients will appear in a plot like below. Regularization for Future Regressors We can add regularization into the future regressors as below. m = m.add_future_regressor(name='A', regularization=0.05) m = m.add_future_regressor(name='B', regularization=0.02) This will add sparsity into the individual regressor coefficients.","title":"Future Regressors"},{"location":"model/future-regressors/#modelling-future-regressors","text":"Future regressors are the external variables which have known future values. In that sense, the future regressors functionality if very similar to special events. The past values of these regressors corresponding to the training time stamps, have to be provided along with the training data itself. See below for an example where we create two dummy regressors A and B by taking rolling means of the original data. df['A'] = df['y'].rolling(7, min_periods=1).mean() df['B'] = df['y'].rolling(30, min_periods=1).mean() The dataframe created likewise, should look like below. ds y A B 0 2007-12-10 9.59076 9.59076 9.59076 1 2007-12-11 8.51959 9.05518 9.05518 2 2007-12-12 8.18368 8.76468 8.76468 3 2007-12-13 8.07247 8.59162 8.59162 4 2007-12-14 7.89357 8.45201 8.45201 In order to perform forecasting, we also need to provide the future values of the regressors. future_regressors_df = pd.DataFrame(data={'A': df['A'][:50], 'B': df['B'][:50]}) This dataframe looks like below. A B 0 9.59076 9.59076 1 9.05518 9.05518 2 8.76468 8.76468 3 8.59162 8.59162 4 8.45201 8.45201 It is a dataframe with only the columns of the future values of the regressors. Similar to events, future regressors too can be added in both the additive and multiplicative formats.","title":"Modelling Future Regressors"},{"location":"model/future-regressors/#additive-future-regressors","text":"The default mode for future regressors in neural_prophet is additive. The regressors have to be added to the NeuralProphet object by calling the add_future_regressor function. Once this is done, the model can be fitted by providing to the fit function, the dataframe of the training data as well as the regressor values. m = NeuralProphet( n_forecasts=3, n_lags=5, ) m = m.add_future_regressor(name='A') m = m.add_future_regressor(name='B') metrics = m.fit(df) When forecasting, the future dataframe must be created by providing the future values of the regressors. To do that, now you need to call the make_future_dataframe function by providing the previously created future_regressors_df as an argument. future = m.make_future_dataframe(df=df, regressors_df=future_regressors_df, future_periods=3) forecast = m.predict(df=future) Now you can plot the components the same way and the resulting plot would look something like below. fig_comp = m.plot_components(forecast) In addition to the components like seasonality, auto-regression and trend it also shows a plot for the additive future regressors. The coefficients of the future regressors can also be plotted. fig_param = m.plot_parameters()","title":"Additive Future Regressors"},{"location":"model/future-regressors/#multiplicative-future-regressors","text":"Future regressors can also be added in multiplicative mode. You simply need to set the mode to multiplicative when adding the regressors to the NeuralProphet object. m = m.add_future_regressor(name='A', mode=\"multiplicative\") m = m.add_future_regressor(name='B') In the above example, we have both additive and multiplicative regressors, where A is multiplicative and B is additive. All the other steps in the fitting and the forecasting processes are the same. The components plot looks as below. There are two individual plots for the additive and multiplicative regressors, where the multiplicative component is shown as a percentage. In the same manner, the coefficients will appear in a plot like below.","title":"Multiplicative Future Regressors"},{"location":"model/future-regressors/#regularization-for-future-regressors","text":"We can add regularization into the future regressors as below. m = m.add_future_regressor(name='A', regularization=0.05) m = m.add_future_regressor(name='B', regularization=0.02) This will add sparsity into the individual regressor coefficients.","title":"Regularization for Future Regressors"},{"location":"model/lagged-regressors/","text":"Modelling Lagged Regressors In the current state of NeuralProphet development, Lagged Regressor support is only available when the AR-Net is enabled. This is because they are both handled in a similar way internally using Feed-Forward Neural Networks and need to specify the n_lags value. For simplicity, at the moment we use the same n_lags value for both the AR-Net and the Lagged Regressors. Therefore, with Lagged Regressors, the NeuralProphet object is instantiated similar with AR-Net like below. m = NeuralProphet( n_forecasts=3, n_lags=5, yearly_seasonality=False, weekly_seasonality=False, daily_seasonality=False, ) When fitting the model, the dataframe provided to the fit function should have additional columns for your lagged regressors like below. ds y A 0 2007-12-10 00:00:00 9.59076 9.59076 1 2007-12-11 00:00:00 8.51959 9.05518 2 2007-12-12 00:00:00 8.18368 8.76468 3 2007-12-13 00:00:00 8.07247 8.59162 4 2007-12-14 00:00:00 7.89357 8.45201 In this example, we have a Lagged Regressor named A . You also need to register these Lagged Regressors with the NeuralProphet object by calling the add_lagged_regressor function and giving the necessary configs. m = m.add_lagged_regressor(name='A') By setting the only_last_value argument of the add_lagged_regressor function, the user can specify either to use same number of lags as auto-regression or use only use last known value as input. Now you can perform the model fitting and forecasting as usual. The plotted components should look like below. You can see the components corresponding to both auto-regression and the Lagged Regressor A . The coefficients plot looks like below. It shows both the AR and Lagged Regressor relevance at the 5 lags. Lagged regressors too can be regularized. This is done by specifying the required regularization strength when registering the lagged regressors with the NeuralProphet object as below. m = m.add_lagged_regressor(name='A', regularization=0.03)","title":"Lagged Regressors"},{"location":"model/lagged-regressors/#modelling-lagged-regressors","text":"In the current state of NeuralProphet development, Lagged Regressor support is only available when the AR-Net is enabled. This is because they are both handled in a similar way internally using Feed-Forward Neural Networks and need to specify the n_lags value. For simplicity, at the moment we use the same n_lags value for both the AR-Net and the Lagged Regressors. Therefore, with Lagged Regressors, the NeuralProphet object is instantiated similar with AR-Net like below. m = NeuralProphet( n_forecasts=3, n_lags=5, yearly_seasonality=False, weekly_seasonality=False, daily_seasonality=False, ) When fitting the model, the dataframe provided to the fit function should have additional columns for your lagged regressors like below. ds y A 0 2007-12-10 00:00:00 9.59076 9.59076 1 2007-12-11 00:00:00 8.51959 9.05518 2 2007-12-12 00:00:00 8.18368 8.76468 3 2007-12-13 00:00:00 8.07247 8.59162 4 2007-12-14 00:00:00 7.89357 8.45201 In this example, we have a Lagged Regressor named A . You also need to register these Lagged Regressors with the NeuralProphet object by calling the add_lagged_regressor function and giving the necessary configs. m = m.add_lagged_regressor(name='A') By setting the only_last_value argument of the add_lagged_regressor function, the user can specify either to use same number of lags as auto-regression or use only use last known value as input. Now you can perform the model fitting and forecasting as usual. The plotted components should look like below. You can see the components corresponding to both auto-regression and the Lagged Regressor A . The coefficients plot looks like below. It shows both the AR and Lagged Regressor relevance at the 5 lags. Lagged regressors too can be regularized. This is done by specifying the required regularization strength when registering the lagged regressors with the NeuralProphet object as below. m = m.add_lagged_regressor(name='A', regularization=0.03)","title":"Modelling Lagged Regressors"},{"location":"model/seasonality/","text":"Modelling Seasonality Seasonality in NeuralProphet is modelled using Fourier terms. It can be specified both in additive and multiplicative modes. Additive Seasonality The default mode for seasonality is additive. See below for a minimalistic example of additive seasonality in NeuralProphet. m = NeuralProphet() metrics = m.fit(df) You can see both the weekly and yearly seasonal shapes, although the weekly pattern is not very clear due to the high frequency. If you do not specify the number of Fourier terms desired for every seasonality, the model assigns default values to them. You can also specify these numbers as in the below example. m = NeuralProphet( yearly_seasonality=8, weekly_seasonality=4 ) According to this example, yearly seasonal pattern will use 8 Fourier terms and the weekly seasonal pattern will use 4 Fourier terms. Multiplicative Seasonality Seasonality can also be modelled multiplicatively by setting the mode explicitly like below. m = NeuralProphet( seasonality_mode='multiplicative' ) Regularize Seasonality Just like all the other components in NeuralProphet, seasonality too can be regularized. This done by regularizing the Fourier coefficients like below. m = NeuralProphet( yearly_seasonality=16, weekly_seasonality=8, daily_seasonality=False, seasonality_reg=1, ) The value of the seasonality_reg parameter can take values in between 0-100. Smaller values (~0.1-1) allow the model to fit larger seasonal fluctuations whereas larger values (~1-100) dampen the seasonality. The default is no regularization.","title":"Seasonality"},{"location":"model/seasonality/#modelling-seasonality","text":"Seasonality in NeuralProphet is modelled using Fourier terms. It can be specified both in additive and multiplicative modes.","title":"Modelling Seasonality"},{"location":"model/seasonality/#additive-seasonality","text":"The default mode for seasonality is additive. See below for a minimalistic example of additive seasonality in NeuralProphet. m = NeuralProphet() metrics = m.fit(df) You can see both the weekly and yearly seasonal shapes, although the weekly pattern is not very clear due to the high frequency. If you do not specify the number of Fourier terms desired for every seasonality, the model assigns default values to them. You can also specify these numbers as in the below example. m = NeuralProphet( yearly_seasonality=8, weekly_seasonality=4 ) According to this example, yearly seasonal pattern will use 8 Fourier terms and the weekly seasonal pattern will use 4 Fourier terms.","title":"Additive Seasonality"},{"location":"model/seasonality/#multiplicative-seasonality","text":"Seasonality can also be modelled multiplicatively by setting the mode explicitly like below. m = NeuralProphet( seasonality_mode='multiplicative' )","title":"Multiplicative Seasonality"},{"location":"model/seasonality/#regularize-seasonality","text":"Just like all the other components in NeuralProphet, seasonality too can be regularized. This done by regularizing the Fourier coefficients like below. m = NeuralProphet( yearly_seasonality=16, weekly_seasonality=8, daily_seasonality=False, seasonality_reg=1, ) The value of the seasonality_reg parameter can take values in between 0-100. Smaller values (~0.1-1) allow the model to fit larger seasonal fluctuations whereas larger values (~1-100) dampen the seasonality. The default is no regularization.","title":"Regularize Seasonality"},{"location":"model/trend/","text":"Modelling Trend This is a minimalistic example of trend modelling in Neuralprophet by defining changepoints. m = NeuralProphet( n_changepoints=100, trend_smoothness=2, yearly_seasonality=False, weekly_seasonality=False, daily_seasonality=False, ) metrics = m.fit(df) future = m.make_future_dataframe(df, future_periods=365, n_historic_predictions=len(df)) forecast = m.predict(future) The components plot looks like below with only trend and residuals as a components. The coefficients plot should show the coefficients corresponding to the 100 changepoints.","title":"Trend"},{"location":"model/trend/#modelling-trend","text":"This is a minimalistic example of trend modelling in Neuralprophet by defining changepoints. m = NeuralProphet( n_changepoints=100, trend_smoothness=2, yearly_seasonality=False, weekly_seasonality=False, daily_seasonality=False, ) metrics = m.fit(df) future = m.make_future_dataframe(df, future_periods=365, n_historic_predictions=len(df)) forecast = m.predict(future) The components plot looks like below with only trend and residuals as a components. The coefficients plot should show the coefficients corresponding to the 100 changepoints.","title":"Modelling Trend"}]}